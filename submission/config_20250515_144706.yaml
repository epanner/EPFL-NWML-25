preprocessing:
  steps:
  - _target_: github_filter
    lowcut: 0.5
    highcut: 120.0
    fs: 1024
    resampleFS: 250
model:
  F1: 16
  D: 2
  eegnet_kernel_size: 32
  eegnet_separable_kernel_size: 16
  eegnet_pooling_1: 8
  eegnet_pooling_2: 4
  dropout_eegnet: 0.3
  MSA_num_heads: 3
  transformer_dim_feedforward: 2048
  num_transformer_layers: 4
  flag_positional_encoding: true
  num_eeg_channels: 19
  sequence_length: 3000
  optimizer:
    lr: 0.0001
  scheduler:
    step_size: 10
    gamma: 0.1
dataset:
  data_path: /home/veit/Uni/Lausanne/NML/EPFL-NWML-25/content/networkML
  train_set: train/train
  test_set: test/test
  distances_set: distances_3d.csv
train:
  max_epochs: 1000
  batch_size: 256
  seed: 42
  prefetch_dataset: true
  gradient_clip_val: 0.5
early_stopping:
  monitor: val_loss
  patience: 50
checkpoint:
  monitor: val_loss
  save_top_k: 1
checkpoint_path: /home/veit/Uni/Lausanne/NML/EPFL-NWML-25/checkpoints/best-checkpoint-2025-05-14_18-56-10.ckpt
